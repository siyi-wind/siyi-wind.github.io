---
layout: archive
title: "Selected Publications"
permalink: /publications/
author_profile: true
---

<style>
/* 全局去掉所有表格边框 */
table, th, td {
  border: none !important;
  border-collapse: collapse !important;
}
table {
  box-shadow: none !important;
  margin-bottom: 1em;
}
td {
  vertical-align: top;
  padding-left: 15px;
}
/* 美化图片 */
img {
  border-radius: 8px;
  box-shadow: none;
  border: none;
}
</style>



<!-- {% if author.googlescholar %}
  You can find my full publication list at  <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %} -->

You can find my full publication list at  <u><a href="https://scholar.google.com/citations?user=zsOt8MYAAAAJ&hl=en">my Google Scholar profile</a>.</u>

<!-- {% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->

<br/>

<!-- STiL -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_CVPR2025_STiL.jpg" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification](https://openaccess.thecvf.com/content/CVPR2025/html/Du_STiL_Semi-supervised_Tabular-Image_Learning_for_Comprehensive_Task-Relevant_Information_Exploration_in_CVPR_2025_paper.html)  
**Siyi Du**, Xinzhe Luo, Declan P. O'Regan, Chen Qin  
*CVPR*, 2025  
[arXiv](http://arxiv.org/abs/2503.06277) / [code](https://github.com/siyi-wind/STiL) / [video](https://www.youtube.com/watch?v=-q3H0M4BpnE)

</td>
</tr>
</table>


<!-- TIP -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_ECCV2024_TIP.jpg" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[TIP: Tabular-Image Pre-training for Multimodal Classification with Incomplete Data](https://dl.acm.org/doi/abs/10.1007/978-3-031-72633-0_27)  
**Siyi Du**, Shaoming Zheng, Yinsong Wang, Wenjia Bai, Declan P. O'Regan, Chen Qin  
*ECCV*, 2024  
[arXiv](http://arxiv.org/abs/2407.07582) / [code](https://github.com/siyi-wind/TIP) / [video](https://www.youtube.com/watch?v=-3_ccGxa4_4)

</td>
</tr>
</table>


<!-- AViT -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MICCAIW2023_AViT.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[AViT: Adapting Vision Transformers for Small Skin Lesion Segmentation Datasets](https://link.springer.com/chapter/10.1007/978-3-031-47401-9_3)  
**Siyi Du**, Nourhan Bayasi, Ghassan Hamarneh, Rafeef Garbi  
*MICCAI 8th ISIC Workshop*, 2023, **Best Paper Award**  
[arXiv](http://arxiv.org/abs/2307.13897) / [code](https://github.com/siyi-wind/AViT)

</td>
</tr>
</table>


<!-- Continual-GEN -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MICCAIW2023_Continual-GEN.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[Continual-GEN: Continual Group Ensembling for Domain-agnostic Skin Lesion Classification](https://link.springer.com/chapter/10.1007/978-3-031-47401-9_1)  
Nourhan Bayasi, **Siyi Du**, Ghassan Hamarneh, Rafeef Garbi  
*MICCAI 8th ISIC Workshop*, 2023, **Oral**  
[pdf](https://workshop2023.isic-archive.com/paper_bayasi.pdf) / [code](https://github.com/nourhanb/Continual-GEN)

</td>
</tr>
</table>



<!-- Master Thesis -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MasterThesis2023.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[Deep Learning for Dermatology: Contributions in Model Fairness, Multi-domain Adaptation, and Light-weight Efficiency](https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/24/items/1.0435879)  
**Siyi Du**  
*Master's Thesis, University of British Columbia*, 2023, **A+**  
[video](https://www.youtube.com/watch?v=0evv4Hy_ZrY)

</td>
</tr>
</table>



<!-- MDViT -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MICCAI2023_MDViT.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets](https://link.springer.com/chapter/10.1007/978-3-031-43901-8_43)  
**Siyi Du**, Nourhan Bayasi, Ghassan Hamarneh, Rafeef Garbi  
*MICCAI*, 2023  
[arXiv](https://arxiv.org/abs/2307.02100) / [code](https://github.com/siyi-wind/MDViT)

</td>
</tr>
</table>



<!-- FairDisCo -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_ECCVW2022_FairDisCo.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[FairDisCo: Fairer AI in Dermatology via Disentanglement Contrastive Learning](https://link.springer.com/chapter/10.1007/978-3-031-25069-9_13)  
**Siyi Du**, Ben Hers, Nourhan Bayasi, Ghassan Hamarneh, Rafeef Garbi  
*ECCV 7th ISIC Workshop*, 2022, **Best Paper Award**  
[arXiv](https://arxiv.org/abs/2208.10013) / [code](https://github.com/siyi-wind/FairDisCo) / [video](https://github.com/siyi-wind/FairDisCo)

</td>
</tr>
</table>



<!-- KBGN -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_ACMMM2020_KBGN.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">

[KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue](https://dl.acm.org/doi/abs/10.1145/3394171.3413826)  
Xiaoze Jiang, **Siyi Du**, Zengchang Qin, Yajing Sun, Jing Yu  
*ACM International Conference on Multimedia (ACM MM)*, 2020, **Oral**  
[arXiv](https://arxiv.org/abs/2008.04858)

</td>
</tr>
</table>

