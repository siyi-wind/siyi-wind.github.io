---
layout: archive
title: "Selected Publications"
permalink: /publications/
author_profile: true
---

<style>
/* 全局去掉所有表格边框 */
table, th, td {
  border: none !important;
  border-collapse: collapse !important;
}
table {
  box-shadow: none !important;
  margin-bottom: 1em;
}
td {
  vertical-align: top;
  padding-left: 15px;
}
/* 美化图片 */
img {
  border-radius: 8px;
  box-shadow: none;
  border: none;
}
</style>



<!-- {% if author.googlescholar %}
  You can find my full publication list at  <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %} -->

You can find my full publication list at  <u><a href="https://scholar.google.com/citations?user=zsOt8MYAAAAJ&hl=en">my Google Scholar profile</a>.</u>

<!-- {% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->

<br/>

<!-- STiL -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_CVPR2025_STiL.jpg" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://openaccess.thecvf.com/content/CVPR2025/html/Du_STiL_Semi-supervised_Tabular-Image_Learning_for_Comprehensive_Task-Relevant_Information_Exploration_in_CVPR_2025_paper.html" target="_blank"><strong>STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification</strong></a><br>
<strong>Siyi Du</strong>, Xinzhe Luo, Declan P. O'Regan, Chen Qin<br>
<em>CVPR</em>, 2025<br>
<a href="http://arxiv.org/abs/2503.06277" target="_blank">arXiv</a> / 
<a href="https://github.com/siyi-wind/STiL" target="_blank">code</a> / 
<a href="https://www.youtube.com/watch?v=-q3H0M4BpnE" target="_blank">video</a>
</td>
</tr>
</table>

<!-- TIP -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_ECCV2024_TIP.jpg" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://dl.acm.org/doi/abs/10.1007/978-3-031-72633-0_27" target="_blank"><strong>TIP: Tabular-Image Pre-training for Multimodal Classification with Incomplete Data</strong></a><br>
<strong>Siyi Du</strong>, Shaoming Zheng, Yinsong Wang, Wenjia Bai, Declan P. O'Regan, Chen Qin<br>
<em>ECCV</em>, 2024<br>
<a href="http://arxiv.org/abs/2407.07582" target="_blank">arXiv</a> / 
<a href="https://github.com/siyi-wind/TIP" target="_blank">code</a> / 
<a href="https://www.youtube.com/watch?v=-3_ccGxa4_4" target="_blank">video</a>
</td>
</tr>
</table>

<!-- AViT -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MICCAIW2023_AViT.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://link.springer.com/chapter/10.1007/978-3-031-47401-9_3" target="_blank"><strong>AViT: Adapting Vision Transformers for Small Skin Lesion Segmentation Datasets</strong></a><br>
<strong>Siyi Du</strong>, Nourhan Bayasi, Ghassan Hamarneh, Rafeef Garbi<br>
<em>MICCAI 8th ISIC Workshop</em>, 2023, <strong>Best Paper Award</strong><br>
<a href="http://arxiv.org/abs/2307.13897" target="_blank">arXiv</a> / 
<a href="https://github.com/siyi-wind/AViT" target="_blank">code</a>
</td>
</tr>
</table>

<!-- Continual-GEN -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MICCAIW2023_Continual-GEN.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://link.springer.com/chapter/10.1007/978-3-031-47401-9_1" target="_blank"><strong>Continual-GEN: Continual Group Ensembling for Domain-agnostic Skin Lesion Classification</strong></a><br>
Nourhan Bayasi, <strong>Siyi Du</strong>, Ghassan Hamarneh, Rafeef Garbi<br>
<em>MICCAI 8th ISIC Workshop</em>, 2023, <strong>Oral</strong><br>
<a href="https://workshop2023.isic-archive.com/paper_bayasi.pdf" target="_blank">pdf</a> / 
<a href="https://github.com/nourhanb/Continual-GEN" target="_blank">code</a>
</td>
</tr>
</table>

<!-- Master Thesis -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MasterThesis2023.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/24/items/1.0435879" target="_blank"><strong>Deep Learning for Dermatology: Contributions in Model Fairness, Multi-domain Adaptation, and Light-weight Efficiency</strong></a><br>
<strong>Siyi Du</strong><br>
<em>Master's Thesis, University of British Columbia</em>, 2023, <strong>A+</strong><br>
<a href="https://www.youtube.com/watch?v=0evv4Hy_ZrY" target="_blank">video</a>
</td>
</tr>
</table>

<!-- MDViT -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_MICCAI2023_MDViT.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://link.springer.com/chapter/10.1007/978-3-031-43901-8_43" target="_blank"><strong>MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets</strong></a><br>
<strong>Siyi Du</strong>, Nourhan Bayasi, Ghassan Hamarneh, Rafeef Garbi<br>
<em>MICCAI</em>, 2023<br>
<a href="https://arxiv.org/abs/2307.02100" target="_blank">arXiv</a> / 
<a href="https://github.com/siyi-wind/MDViT" target="_blank">code</a>
</td>
</tr>
</table>

<!-- FairDisCo -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_ECCVW2022_FairDisCo.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://link.springer.com/chapter/10.1007/978-3-031-25069-9_13" target="_blank"><strong>FairDisCo: Fairer AI in Dermatology via Disentanglement Contrastive Learning</strong></a><br>
<strong>Siyi Du</strong>, Ben Hers, Nourhan Bayasi, Ghassan Hamarneh, Rafeef Garbi<br>
<em>ECCV 7th ISIC Workshop</em>, 2022, <strong>Best Paper Award</strong><br>
<a href="https://arxiv.org/abs/2208.10013" target="_blank">arXiv</a> / 
<a href="https://github.com/siyi-wind/FairDisCo" target="_blank">code</a> / 
<a href="https://github.com/siyi-wind/FairDisCo" target="_blank">video</a>
</td>
</tr>
</table>

<!-- KBGN -->
<table>
<tr>
<td style="width: 250px;">
<img src="/images/siyi_ACMMM2020_KBGN.png" width="250">
</td>
<td style="vertical-align: top; padding-left: 15px;">
<a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413826" target="_blank"><strong>KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue</strong></a><br>
Xiaoze Jiang, <strong>Siyi Du</strong>, Zengchang Qin, Yajing Sun, Jing Yu<br>
<em>ACM International Conference on Multimedia (ACM MM)</em>, 2020, <strong>Oral</strong><br>
<a href="https://arxiv.org/abs/2008.04858" target="_blank">arXiv</a>
</td>
</tr>
</table>